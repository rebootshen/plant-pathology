{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "#####################################\n",
    "# Libraries\n",
    "#####################################\n",
    "# Common libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Image processing\n",
    "import imageio\n",
    "import cv2\n",
    "import skimage.transform\n",
    "#from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "# Charts\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML, statistics\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "\n",
    "# Tensorflow\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "INPUT_DIR = \"/kaggle/input/plant-pathology-2021-fgvc8/\"\n",
    "PRETRAINED_DIR = \"/kaggle/input/pretrained-model/\"\n",
    "\n",
    "NUM_CLASSES = 6 #12\n",
    "IMAGE_SIZE= (224,224)  #(256,256)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"\n",
    "    Create and fit the model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        #(18632, 2) (17700, 2) (932, 2)\n",
    "        #15930 , 1770, 932\n",
    "        \n",
    "        self.nb_train_samples = 15930 #4275 #32706\n",
    "        self.nb_validation_samples = 1770 #475 #10902\n",
    "        self.batch_size=512 #512 #32 #1024   #32\n",
    "               \n",
    "        \n",
    "        self.img_width = IMAGE_SIZE[0]\n",
    "        self.img_height = IMAGE_SIZE[1]\n",
    "        print(self.img_width,self.img_height)\n",
    "        \n",
    "    \n",
    "    def create_model(self, model_name):\n",
    "        if model_name == \"Xception\" :\n",
    "                model = self.create_model_1()\n",
    "        elif model_name == \"XceptionDenseNet121\": \n",
    "                model = self.create_model_3()\n",
    "        else:\n",
    "                print(\"Model not found\")\n",
    "        self.model_name = model_name\n",
    "        return model\n",
    "    \n",
    "\n",
    "    #Total params: 20,886,068\n",
    "    def create_model_1(self):\n",
    "        pretrained_model = tf.keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(self.img_width, self.img_height, 3))\n",
    "        model = tf.keras.models.Sequential([\n",
    "            pretrained_model,\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')\n",
    "        ])\n",
    "    \n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        #tf.keras.utils.plot_model(densenet_model, to_file='densenet_model.png')\n",
    "        return model\n",
    "\n",
    "    def create_model_3(self):\n",
    "        path1 = PRETRAINED_DIR + 'xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "        xception_model = tf.keras.models.Sequential([\n",
    "           tf.keras.applications.xception.Xception(include_top=False, weights=path1, input_shape=(self.img_width, self.img_height, 3)),#(512, 512, 3)),\n",
    "           tf.keras.layers.GlobalAveragePooling2D(),\n",
    "           #tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')\n",
    "           tf.keras.layers.Dense(NUM_CLASSES,activation='sigmoid')\n",
    "        ])\n",
    "        # Freezing the weights\n",
    "        #for layer in xception_model.layers[:-1]:\n",
    "        #    layer.trainable=False\n",
    "            \n",
    "        #xception_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        #xception_model.summary()\n",
    "        path2 = PRETRAINED_DIR + 'densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "        densenet_model = tf.keras.models.Sequential([\n",
    "            tf.keras.applications.densenet.DenseNet121(include_top=False, weights=path2,input_shape=(self.img_width, self.img_height, 3)),#(512, 512, 3)),\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            #tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')\n",
    "            tf.keras.layers.Dense(NUM_CLASSES,activation='sigmoid')\n",
    "        ])\n",
    "        #for layer in densenet_model.layers[:-1]:\n",
    "        #    layer.trainable=False\n",
    "        #densenet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        #densenet_model.summary()\n",
    "        \n",
    "        inputs = tf.keras.Input(shape=(self.img_width, self.img_height, 3)) #(512, 512, 3))\n",
    "\n",
    "        xception_output = xception_model(inputs)\n",
    "        densenet_output = densenet_model(inputs)\n",
    "\n",
    "        outputs = tf.keras.layers.average([densenet_output, xception_output])\n",
    "\n",
    "\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModelTrainer()\n",
    "model = trainer.create_model(\"XceptionDenseNet121\") # 0.9062 Total params: 27,935,872\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.load_weights('/kaggle/input/pretrained-model/best_XceptionDenseNet121_v2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "test_dir = '/kaggle/input/plant-pathology-2021-fgvc8/test_images/'\n",
    "test_df = pd.DataFrame()\n",
    "test_df['image'] = os.listdir(test_dir)\n",
    "\n",
    "IMSIZES = (224, 240, 260, 300, 380, 456, 528, 600)\n",
    "im_size = IMSIZES[7]\n",
    "\n",
    "testgen = ImageDataGenerator(\n",
    "            #preprocessing_function = tf.keras.applications.xception.preprocess_input,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            brightness_range=(0.8, 1.2),\n",
    "            rescale=1/255.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes = ['complex', 'frog_eye_leaf_spot', 'frog_eye_leaf_spot complex', 'healthy', 'powdery_mildew', 'powdery_mildew complex', 'rust', 'rust complex', 'rust frog_eye_leaf_spot', 'scab', 'scab frog_eye_leaf_spot', 'scab frog_eye_leaf_spot complex']\n",
    "classes = ['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab'] #,'frog_eye_leaf_spot complex','powdery_mildew complex', 'rust complex', 'rust frog_eye_leaf_spot', 'scab frog_eye_leaf_spot', 'scab frog_eye_leaf_spot complex']\n",
    "\n",
    "class Submitter:\n",
    "    \"\"\"\n",
    "    Predict and submit\n",
    "    \"\"\"\n",
    "    def __init__(self, model, img_size):\n",
    "        self.model = model\n",
    "        batch_size=BATCH_SIZE\n",
    "        print(\"Initializing submitter\")\n",
    "        #Submission generator\n",
    "        # flow_from_directory for input/test didn't work for me, so quick fix is to use flow_from_dataframe with list of files\n",
    "        # Load list of files from test folder into dataframe\n",
    "        self.test_files_df=pd.DataFrame()\n",
    "        TEST_DIR = INPUT_DIR + 'test_images/'\n",
    "        self.test_files_df['image']=os.listdir(TEST_DIR)\n",
    "        print(\"Loaded test files list\")\n",
    "        \n",
    "        \n",
    "        # Create generator in it\n",
    "        #self.generator=ImageDataGenerator(rescale=1./255.).flow_from_dataframe(\n",
    "        _test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "        self.generator = _test_datagen.flow_from_dataframe(\n",
    "                    dataframe=self.test_files_df,\n",
    "                    directory=TEST_DIR,\n",
    "                    x_col=\"image\",\n",
    "                    y_col=None,\n",
    "                    #has_ext=True,\n",
    "                    class_mode=None,\n",
    "                    batch_size=batch_size,\n",
    "                    seed=42,\n",
    "                    shuffle=False,\n",
    "                    target_size=img_size)    \n",
    "        \n",
    "        print('Submission generator created')    \n",
    "\n",
    "\n",
    "    def predict_for_submit(self):\n",
    "        \"\"\"\n",
    "        Predict submission test data and form dataframe to submit\n",
    "        \"\"\"\n",
    "        print(\"Forming submission dataframe...\")\n",
    "        # Predict\n",
    "        y_pred = self.model.predict(self.generator)\n",
    "        y_pred = y_pred.tolist()\n",
    "        print(y_pred)\n",
    "        #y_pred = np.argmax(y_pred, axis=1)\n",
    "        #print(y_pred)\n",
    "        \n",
    "        indices = []\n",
    "        for pred in y_pred:\n",
    "            temp = []\n",
    "            for category in pred:\n",
    "                #print(category)\n",
    "                if category>=0.3:\n",
    "                    temp.append(pred.index(category))\n",
    "            #print(temp)\n",
    "            if temp!=[]:\n",
    "                indices.append(temp)\n",
    "            else:\n",
    "                temp.append(np.argmax(pred))\n",
    "                indices.append(temp)\n",
    "        \n",
    "        print(indices)\n",
    "        \n",
    "        y_pred_str = []        \n",
    "        for image in indices:\n",
    "            temp = []\n",
    "            for i in image:\n",
    "                #if i > 5:\n",
    "                #    temp.append(classes[0])\n",
    "                #else:\n",
    "                temp.append(classes[i])\n",
    "                    \n",
    "            y_pred_str.append(' '.join(temp))\n",
    "\n",
    "        print(y_pred_str)\n",
    "        \n",
    "        self.test_files_df['labels'] = y_pred_str\n",
    "        # Write to csv\n",
    "        self.test_files_df.to_csv('./submission.csv', index=False)\n",
    "        print(\"Submission completed: written submission.csv\")\n",
    "        return self.test_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframe for submission\n",
    "submitter = Submitter(model, IMAGE_SIZE)\n",
    "submission_df = submitter.predict_for_submit()     \n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp /kaggle/input/notebook-sam/best_XceptionDenseNet121.h5 .\n",
    "\n",
    "#import os\n",
    "#print(os.listdir(\"/kaggle/input/\"))\n",
    "#os.chdir(r'/kaggle/working')\n",
    "#from IPython.display import FileLink\n",
    "#FileLink(r'./best_XceptionDenseNet121.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
