{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#####################################\n# Libraries\n#####################################\n# Common libs\nimport pandas as pd\nimport numpy as np\nimport sys\nimport os\nimport random\nfrom pathlib import Path\n\n# Image processing\nimport imageio\nimport cv2\nimport skimage.transform\n#from skimage.transform import rescale, resize, downscale_local_mean\n\n# Charts\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# ML, statistics\nimport scipy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n\n# Tensorflow\n#from sklearn.preprocessing import OneHotEncoder\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam, RMSprop\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nINPUT_DIR = \"/kaggle/input/plant-pathology-2021-fgvc8/\"\nPRETRAINED_DIR = \"/kaggle/input/pretrained-model/\"\n\nNUM_CLASSES = 6 #12\nIMAGE_SIZE= (224,224)  #(256,256)\n\nBATCH_SIZE = 32\n\n\n\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"class ModelTrainer:\n    \"\"\"\n    Create and fit the model\n    \"\"\"\n    \n    def __init__(self):\n        #(18632, 2) (17700, 2) (932, 2)\n        #15930 , 1770, 932\n        \n        self.nb_train_samples = 15930 #4275 #32706\n        self.nb_validation_samples = 1770 #475 #10902\n        self.batch_size=512 #512 #32 #1024   #32\n               \n        \n        self.img_width = IMAGE_SIZE[0]\n        self.img_height = IMAGE_SIZE[1]\n        print(self.img_width,self.img_height)\n        \n    \n    def create_model(self, model_name):\n        if model_name == \"Xception\" :\n                model = self.create_model_1()\n        elif model_name == \"XceptionDenseNet121\": \n                model = self.create_model_3()\n        else:\n                print(\"Model not found\")\n        self.model_name = model_name\n        return model\n    \n\n    #Total params: 20,886,068\n    def create_model_1(self):\n        pretrained_model = tf.keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(self.img_width, self.img_height, 3))\n        model = tf.keras.models.Sequential([\n            pretrained_model,\n            tf.keras.layers.GlobalAveragePooling2D(),\n            tf.keras.layers.Dropout(0.3),\n            tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')\n        ])\n    \n        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n        #tf.keras.utils.plot_model(densenet_model, to_file='densenet_model.png')\n        return model\n\n    def create_model_3(self):\n        path1 = PRETRAINED_DIR + 'xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n        xception_model = tf.keras.models.Sequential([\n           tf.keras.applications.xception.Xception(include_top=False, weights=None, input_shape=(self.img_width, self.img_height, 3)),#(512, 512, 3)),\n           tf.keras.layers.GlobalAveragePooling2D(),\n           #tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')\n           tf.keras.layers.Dense(NUM_CLASSES,activation='sigmoid')\n        ])\n        # Freezing the weights\n        #for layer in xception_model.layers[:-1]:\n        #    layer.trainable=False\n            \n        #xception_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n        #xception_model.summary()\n        path2 = PRETRAINED_DIR + 'densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'\n        densenet_model = tf.keras.models.Sequential([\n            tf.keras.applications.densenet.DenseNet121(include_top=False, weights=None,input_shape=(self.img_width, self.img_height, 3)),#(512, 512, 3)),\n            tf.keras.layers.GlobalAveragePooling2D(),\n            #tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')\n            tf.keras.layers.Dense(NUM_CLASSES,activation='sigmoid')\n        ])\n        #for layer in densenet_model.layers[:-1]:\n        #    layer.trainable=False\n        #densenet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n        #densenet_model.summary()\n        \n        inputs = tf.keras.Input(shape=(self.img_width, self.img_height, 3)) #(512, 512, 3))\n\n        xception_output = xception_model(inputs)\n        densenet_output = densenet_model(inputs)\n\n        outputs = tf.keras.layers.average([densenet_output, xception_output])\n\n\n        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n        return model","metadata":{"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def get_pred_label(y_pred):\n    indices = []\n    for pred in y_pred:\n        temp = []\n        for category in pred:\n            #print(category)\n            if category>=0.3:\n                temp.append(pred.index(category))\n        #print(temp)\n        if temp!=[]:\n            indices.append(temp)\n        else:\n            temp.append(np.argmax(pred))\n            indices.append(temp)\n    y_pred_str = []        \n    for image in indices:\n        temp = []\n        for i in image:\n            #if i > 5:\n            #    temp.append(classes[0])\n            #else:\n            temp.append(classes[i])\n\n        y_pred_str.append(' '.join(temp))\n\n    #print(y_pred_str)\n    return y_pred_str\n\nclasses = ['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab'] #,'frog_eye_leaf_spot complex','powdery_mildew complex', 'rust complex', 'rust frog_eye_leaf_spot', 'scab frog_eye_leaf_spot', 'scab frog_eye_leaf_spot complex']\n\ntest_files_df=pd.DataFrame()\nTEST_DIR = INPUT_DIR + 'test_images/'\ntest_files_df['image']=os.listdir(TEST_DIR)\n        \ntestgen = ImageDataGenerator(\n            rescale=1/255.0)\n\ntest_generator = testgen.flow_from_dataframe(\n    dataframe=test_files_df,\n    directory=TEST_DIR,\n    x_col=\"image\",\n    y_col=None,\n    batch_size=BATCH_SIZE,\n    seed=42,\n    shuffle=False, #True,\n    class_mode=None,\n    target_size=IMAGE_SIZE)","metadata":{"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Found 3 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = ModelTrainer()\nmodel1 = trainer.create_model(\"XceptionDenseNet121\") # 0.9062 Total params: 27,935,872\nmodel1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel1.load_weights(PRETRAINED_DIR + 'best_XceptionDenseNet121_v2.h5')\n\nmodel2 = trainer.create_model(\"XceptionDenseNet121\") # 0.9062 Total params: 27,935,872\nmodel2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel2.load_weights(PRETRAINED_DIR + 'best_XceptionDenseNet121_v21.h5')\n\nmodel3 = trainer.create_model(\"XceptionDenseNet121\") # 0.9062 Total params: 27,935,872\nmodel3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel3.load_weights(PRETRAINED_DIR + 'best_XceptionDenseNet121_v23.h5')\n\nfold_var = 3 \npreds = []\n\nfor i in range(fold_var):\n    preds.append(model1.predict(test_generator))\n    preds.append(model2.predict(test_generator))\n    preds.append(model3.predict(test_generator))\n    \npred = np.mean(np.array(preds), axis=0)\n\nprint(pred)\npred = pred.tolist()\ntestlabels = get_pred_label(pred)\nprint(testlabels)\n        \ntest_files_df['labels'] = testlabels #y_pred_str\n# Write to csv\ntest_files_df.to_csv('./submission.csv', index=False)\nprint(\"Submission completed: written submission.csv\")","metadata":{"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"224 224\n[[7.6000303e-01 5.1878035e-01 1.0822977e-04 5.8096820e-03 1.9374636e-03\n  4.3127462e-01]\n [2.0496781e-01 8.9322662e-01 6.6006622e-05 1.2648279e-04 3.6663313e-03\n  3.2507986e-02]\n [1.1687552e-02 5.0737113e-03 9.9193268e-02 8.1207855e-03 3.9434247e-03\n  8.3064878e-01]]\n['complex frog_eye_leaf_spot scab', 'frog_eye_leaf_spot', 'scab']\nSubmission completed: written submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get dataframe for submission\nsubmitter = Submitter(model, IMAGE_SIZE)\nsubmission_df = submitter.predict_for_submit()     \nsubmission_df.head()","metadata":{"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Initializing submitter\nLoaded test files list\nFound 3 validated image filenames.\nSubmission generator created\nForming submission dataframe...\n[[0.8010386228561401, 0.5480356216430664, 0.00012068660726072267, 0.0009187542600557208, 0.00139617919921875, 0.42991578578948975], [0.1674143671989441, 0.9821889996528625, 0.00013410155952442437, 0.0003273215552326292, 0.0019570142030715942, 0.019639434292912483], [0.0016907602548599243, 0.0028885751962661743, 0.09923925995826721, 0.0012562423944473267, 0.0018715758342295885, 0.8805564045906067]]\n[[0, 1, 5], [1], [5]]\n['complex frog_eye_leaf_spot scab', 'frog_eye_leaf_spot', 'scab']\nSubmission completed: written submission.csv\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"                  image                           labels\n0  ad8770db05586b59.jpg  complex frog_eye_leaf_spot scab\n1  c7b03e718489f3ca.jpg               frog_eye_leaf_spot\n2  85f8cb619c66b863.jpg                             scab","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ad8770db05586b59.jpg</td>\n      <td>complex frog_eye_leaf_spot scab</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c7b03e718489f3ca.jpg</td>\n      <td>frog_eye_leaf_spot</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>85f8cb619c66b863.jpg</td>\n      <td>scab</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#!cp /kaggle/input/notebook-sam/best_XceptionDenseNet121.h5 .\n\n#import os\n#print(os.listdir(\"/kaggle/input/\"))\n#os.chdir(r'/kaggle/working')\n#from IPython.display import FileLink\n#FileLink(r'./best_XceptionDenseNet121.h5')","metadata":{"trusted":true},"execution_count":44,"outputs":[]}]}