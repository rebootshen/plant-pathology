{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Libraries and Setting\n",
    ">Although the use of pre-trained models for transfer learning has achieved good results, the training of deep neural networks is very time-consuming. We hope to explore another classification method, which is to use the pre-trained model to extract the feature information of the picture, and finally try to mix multiple feature information under different models to obtain stronger feature information. Although the improvement in accuracy is very limited in the result, this process is instructive. I believe that with more diverse models and more sufficient feature information, the final accuracy rate can continue to be improved.\n",
    "\n",
    ">In addition, due to the huge amount of data, even using the extracted features to train the classifier is very time-consuming. Therefore, we do not use cross-validation in this part, so by adjusting the parameters of the classifier, the accuracy can also be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since we subsequently train the traditional classifiers on the extracted features in the local CPU environment and the GPU environment provided by kaggle, we need to clarify the current environment at the beginning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_KAGGLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this step, we imported the commonly used libraries, set some basic parameters for subsequent use, and configured the corresponding path according to the current environment. Finally we verified the path and printed the basic structure of the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best_EfficientNetB7.h5', 'best_XceptionDenseNet121.h5']\n",
      "['sample_submission.csv', 'test_images', 'train.csv', 'train_images']\n",
      "(18632, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800113bb65efe69e.jpg</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8002cb321f8bfcdf.jpg</td>\n",
       "      <td>scab frog_eye_leaf_spot complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80070f7fb5e2ccaa.jpg</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80077517781fb94f.jpg</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800cbf0ff87721f8.jpg</td>\n",
       "      <td>complex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image                           labels\n",
       "0  800113bb65efe69e.jpg                          healthy\n",
       "1  8002cb321f8bfcdf.jpg  scab frog_eye_leaf_spot complex\n",
       "2  80070f7fb5e2ccaa.jpg                             scab\n",
       "3  80077517781fb94f.jpg                             scab\n",
       "4  800cbf0ff87721f8.jpg                          complex"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "#####################################\n",
    "# Libraries\n",
    "#####################################\n",
    "# Common libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Image processing\n",
    "import imageio\n",
    "import cv2\n",
    "import skimage.transform\n",
    "#from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "# Charts\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML, statistics\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "\n",
    "# Tensorflow\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import time\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "if USE_KAGGLE == True:\n",
    "    INPUT_DIR = \"../input/plant-pathology-2021-fgvc8/\"\n",
    "    PRETRAINED_DIR = \"../input/pretrained-model/\"\n",
    "    OUTPUT_DIR =\"./\"\n",
    "    FEATURES_DIR = \"../input/features/\"\n",
    "else:\n",
    "    INPUT_DIR = \"./plant-pathology-2021-fgvc8/\"\n",
    "    PRETRAINED_DIR = \"./pretrained-model/\"\n",
    "    OUTPUT_DIR =\"./working/\"\n",
    "    FEATURES_DIR = \"./features/\"\n",
    "#INPUT_DIR = \"../input/plant-pathology-2021-fgvc8/\"\n",
    "#INPUT_DIR = \"./plant-pathology-2021-fgvc8/\"\n",
    "#INPUT_DIR = \"./archive/\"\n",
    "#PRETRAINED_DIR = \"../input/pretrained-model/\"\n",
    "#PRETRAINED_DIR = \"./pretrained-model/\"\n",
    "#OUTPUT_DIR =\"../working/\"\n",
    "#OUTPUT_DIR =\"./working/\"\n",
    "#INPUT_DIR = \"../input/plant-pathology-2021-fgvc8/\"\n",
    "#PRETRAINED_DIR = \"../pretrained/\"\n",
    "#OUTPUT_DIR = \"./model/\"\n",
    "\n",
    "\n",
    "TRAIN_DATA_DIR = INPUT_DIR + 'train_images'\n",
    "#TRAIN_DATA_DIR = INPUT_DIR + 'img_sz_256'\n",
    "#TRAIN_DATA_DIR = INPUT_DIR + 'img_sz_512'\n",
    "\n",
    "\n",
    "IMSIZES = (224, 240, 260, 300, 380, 456, 528, 600)\n",
    "\n",
    "NUM_CLASSES = 12\n",
    "IMAGE_SIZE= (224,224)  #(256,256)\n",
    "\n",
    "BATCH_SIZE = 16 #32  16\n",
    "TRAIN_BATCH_SIZE = 512 #512 256\n",
    "#16ï¼Œ512 works\n",
    "\n",
    "print(os.listdir(OUTPUT_DIR))\n",
    "print(os.listdir(INPUT_DIR))\n",
    "\n",
    "toy=False\n",
    "\n",
    "all_df = pd.read_csv(INPUT_DIR + \"train.csv\")\n",
    "if toy:\n",
    "    all_df = all_df.sample(5000)\n",
    "\n",
    "\n",
    "NB_TRAIN = all_df.shape[0]  #15930 #4275 #32706\n",
    "NB_VALID = NB_TRAIN * 0.1 #1770 #475 #10902\n",
    "\n",
    "print(all_df.shape)\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DataPreparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, the data set is divided into a training set and a test set to facilitate the calculation of accuracy locally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17700, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18632, 2) (17700, 2) (932, 2)\n"
     ]
    }
   ],
   "source": [
    "class DataPreparation:\n",
    "    \"\"\"\n",
    "    Train/test\n",
    "    \"\"\"\n",
    "    def train_test_split(self, all_df):\n",
    "        \"\"\"\n",
    "        Balanced split to train, test and val\n",
    "        \"\"\"\n",
    "        # Split to train and test before balancing\n",
    "        train_df, test_df = train_test_split(all_df, random_state=24, test_size=0.05, shuffle=False)\n",
    "        print(train_df.shape)\n",
    "#         # Split train to train and validation datasets\n",
    "#         train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=24)\n",
    "        # Number of samples in each category\n",
    "        \n",
    "        #ncat_bal = train_df['labels'].value_counts().max()\n",
    "#        #ncat_bal = int(len(train_df)/train_df['label'].cat.categories.size)\n",
    "        #train_df = train_df.groupby('labels', as_index=False).apply(lambda g:  g.sample(ncat_bal, replace=True, random_state=24)).reset_index(drop=True)\n",
    "        #print(train_df.shape, ncat_bal)\n",
    "        return train_df, test_df\n",
    "    \n",
    "    def plot_balanced(self, train_df, all_df):\n",
    "        \"\"\"\n",
    "        Plot samples per category before and after balancing\n",
    "        \"\"\"\n",
    "        f, axs = plt.subplots(1,2,figsize=(15,4))\n",
    "        # Before balancing\n",
    "        all_df.labels.value_counts().plot(kind='bar', ax=axs[0])\n",
    "        axs[0].set_title('All labels')\n",
    "        axs[0].set_xlabel('Label')\n",
    "        axs[0].set_ylabel('Count')\n",
    "        # After balancing\n",
    "        train_df.labels.value_counts().plot(kind='bar', ax=axs[1])\n",
    "        axs[1].set_title('Train labels after balancing')\n",
    "        axs[1].set_xlabel('Label')\n",
    "        axs[1].set_ylabel('Count')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Train/test/validation split with balanced labels in train\n",
    "data_prep = DataPreparation()\n",
    "train_df, test_df = data_prep.train_test_split(all_df)\n",
    "\n",
    "# Plot before and after balancing\n",
    "data_prep.plot_balanced(train_df, all_df)\n",
    "print(all_df.shape,train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After that, we created the Generators class, which contains a basic ImageDataGenerator to implement basic data augmentation. On this basis, we inherited it and used flow_from_dataframe() to obtain three subset generators. They read in the data in the form of batches and preprocessed them for output. This is very friendly for memory management when the amount of data is large.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15930 validated image filenames belonging to 12 classes.\n",
      "Train generator created\n",
      "Found 1770 validated image filenames belonging to 12 classes.\n",
      "Validation generator created\n",
      "Found 932 validated image filenames belonging to 12 classes.\n",
      "Test generator created\n",
      "Generators created\n"
     ]
    }
   ],
   "source": [
    "class Generators:\n",
    "    \"\"\"\n",
    "    Train, validation and test generators\n",
    "    \"\"\"\n",
    "    def __init__(self, train_df, test_df):\n",
    "        self.batch_size= BATCH_SIZE #16 #1024 #32 #8\n",
    "        self.img_size= IMAGE_SIZE #(256,256)#(512,512)#(192,128) #(96,64) (384,256)  #(4000,2672)\n",
    "\n",
    "        # Base train/validation generator\n",
    "        _datagen = ImageDataGenerator(\n",
    "            rescale=1./255.,\n",
    "            validation_split=0.1,\n",
    "            #featurewise_center=False,\n",
    "            #featurewise_std_normalization=False,\n",
    "            fill_mode='nearest',\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=10, #180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            zoom_range = 0.15, # Randomly zoom image \n",
    "            width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=True  # randomly flip images\n",
    "            )\n",
    " \n",
    "        # Train generator\n",
    "        self.train_generator = _datagen.flow_from_dataframe(\n",
    "            dataframe=train_df, #all_df, #\n",
    "            directory=TRAIN_DATA_DIR,\n",
    "            x_col=\"image\",\n",
    "            y_col=\"labels\",\n",
    "            #has_ext=False,\n",
    "            \n",
    "            subset=\"training\",\n",
    "            batch_size=self.batch_size,\n",
    "            seed=42,\n",
    "            shuffle=False, #True,\n",
    "            class_mode=\"categorical\",\n",
    "            target_size=self.img_size)\n",
    "        print('Train generator created')\n",
    "        # Validation generator\n",
    "        self.val_generator = _datagen.flow_from_dataframe(\n",
    "            dataframe=train_df,#test_df ,#\n",
    "            directory=TRAIN_DATA_DIR,\n",
    "            x_col=\"image\",\n",
    "            y_col=\"labels\",\n",
    "            #has_ext=False,\n",
    "            \n",
    "            subset=\"validation\",\n",
    "            batch_size=self.batch_size,\n",
    "            seed=42,\n",
    "            shuffle=False, #True,\n",
    "            class_mode=\"categorical\",\n",
    "            target_size=self.img_size)    \n",
    "        print('Validation generator created')\n",
    "        \n",
    "        \n",
    "        # Test generator\n",
    "        _test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "        self.test_generator = _test_datagen.flow_from_dataframe(\n",
    "            dataframe=test_df,\n",
    "            directory=TRAIN_DATA_DIR,\n",
    "            x_col=\"image\",\n",
    "            y_col='labels',\n",
    "            #has_ext=False,\n",
    "            class_mode=\"categorical\",\n",
    "            batch_size=self.batch_size,\n",
    "            seed=42,\n",
    "            shuffle=False,\n",
    "            target_size=self.img_size)     \n",
    "        print('Test generator created')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# Create generators   \n",
    "#(43608, 2) (4658, 2)\n",
    "generators = Generators(train_df, test_df)\n",
    "print(\"Generators created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate Features\n",
    ">In this part, we first specify the required pre-training model and remove the classification layer to obtain our feature generator. Then we use the Generators class created earlier to read in the data in batch size, expand the dimensions, call the preprocessing method of the corresponding model, and finally generate features for each picture and save it with the list. It is worth noting that since we do not use the validation set in this part, the validation set and the training set are merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.applications.vgg16 as vgg16\n",
    "import tensorflow.keras.applications.resnet_v2 as resnet_v2\n",
    "import tensorflow.keras.applications.densenet as densenet\n",
    "import tensorflow.keras.applications.inception_resnet_v2 as inception_resnet_v2\n",
    "import tensorflow.keras.applications.xception as xception\n",
    "import tensorflow.keras.applications.mobilenet_v2 as mobilenet_v2\n",
    "import tensorflow.keras.applications.efficientnet as efficientnet\n",
    "import xgboost as xgb\n",
    "from numpy import logspace\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#efficientnet.EfficientNetB7\n",
    "#mobilenet_v2.MobileNetV2\n",
    "#xception.Xception\n",
    "#densenet.DenseNet121\n",
    "#resnet_v2.ResNet50V2\n",
    "#vgg16.VGG16\n",
    "#inception_resnet_v2.InceptionResNetV2\n",
    "\n",
    "pre_trained_model = densenet\n",
    "pre_trained_model_type = densenet.DenseNet121\n",
    "pre_trained_model_type_name = 'DenseNet121'\n",
    "\n",
    "if USE_KAGGLE == True:\n",
    "    path = PRETRAINED_DIR + 'densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    cls_model_f = pre_trained_model_type(weights=path,\n",
    "                              include_top=False, # remove the classification layer\n",
    "                              pooling='avg', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "else:\n",
    "    cls_model_f = pre_trained_model_type(weights='imagenet',\n",
    "                              include_top=False, # remove the classification layer\n",
    "                              pooling='avg', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "\n",
    "classes_2 = ['complex', 'frog_eye_leaf_spot', 'frog_eye_leaf_spot complex', 'healthy', \n",
    "             'powdery_mildew', 'powdery_mildew complex', 'rust', 'rust complex', 'rust frog_eye_leaf_spot', \n",
    "             'scab', 'scab frog_eye_leaf_spot', 'scab frog_eye_leaf_spot complex']\n",
    "def get_class_2(one_hot):\n",
    "    for i in range(NUM_CLASSES):\n",
    "        if one_hot[i] == 1:\n",
    "            return classes_2[i]\n",
    "def get_class_index(one_hot):\n",
    "    for i in range(NUM_CLASSES):\n",
    "        if one_hot[i] == 1:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_fea = []\n",
    "testX_fea = []\n",
    "trainY_cls = []\n",
    "testY_cls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15930 , 1770, 932\n",
    "train_set_len = int(train_df.shape[0]*0.9)\n",
    "val_set_len = int(train_df.shape[0]*0.1)\n",
    "test_set_len = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "# By using subset, train_generator just get 15930 images\n",
    "#train_iternum = train_set_len//16\n",
    "#val_iternum = val_set_len//16\n",
    "train_iternum = train_set_len//BATCH_SIZE\n",
    "val_iternum = val_set_len//BATCH_SIZE\n",
    "\n",
    "\n",
    "#train_set\n",
    "for i in range(train_iternum):\n",
    "    print(i)\n",
    "    img_batch, label_batch = generators.train_generator.next()\n",
    "    for j in range(len(img_batch)):\n",
    "        img_batch[j] = tf.expand_dims(img_batch[j], axis=0) \n",
    "        img_batch[j] = pre_trained_model.preprocess_input(img_batch[j])\n",
    "\n",
    "    tmp = cls_model_f.predict(img_batch)\n",
    "    for j in range(len(tmp)):\n",
    "        trainX_fea.append(tmp[j])\n",
    "        \n",
    "    for j in range(len(label_batch)):\n",
    "        trainY_cls.append(get_class_index(label_batch[j]))\n",
    "\n",
    "img_batch, label_batch = generators.train_generator.next()\n",
    "for j in range(len(img_batch)):\n",
    "    img_batch[j] = tf.expand_dims(img_batch[j], axis=0) \n",
    "    img_batch[j] = pre_trained_model.preprocess_input(img_batch[j])\n",
    "\n",
    "tmp = cls_model_f.predict(img_batch)\n",
    "for j in range(train_set_len - BATCH_SIZE*train_iternum):\n",
    "    trainX_fea.append(tmp[j])\n",
    "\n",
    "for j in range(train_set_len - BATCH_SIZE*train_iternum):\n",
    "    trainY_cls.append(get_class_index(label_batch[j]))\n",
    "    \n",
    "    \n",
    "#val_set   \n",
    "for i in range(val_iternum):\n",
    "    print(i)\n",
    "    img_batch, label_batch = generators.val_generator.next()\n",
    "    for j in range(len(img_batch)):\n",
    "        img_batch[j] = tf.expand_dims(img_batch[j], axis=0) \n",
    "        img_batch[j] = pre_trained_model.preprocess_input(img_batch[j])\n",
    "\n",
    "    tmp = cls_model_f.predict(img_batch)\n",
    "    for j in range(len(tmp)):\n",
    "        trainX_fea.append(tmp[j])\n",
    "        \n",
    "    for j in range(len(label_batch)):\n",
    "        trainY_cls.append(get_class_index(label_batch[j]))\n",
    "\n",
    "img_batch, label_batch = generators.val_generator.next()\n",
    "for j in range(len(img_batch)):\n",
    "    img_batch[j] = tf.expand_dims(img_batch[j], axis=0) \n",
    "    img_batch[j] = pre_trained_model.preprocess_input(img_batch[j])\n",
    "\n",
    "tmp = cls_model_f.predict(img_batch)\n",
    "for j in range(val_set_len - BATCH_SIZE*val_iternum):\n",
    "    trainX_fea.append(tmp[j])\n",
    "\n",
    "for j in range(val_set_len - BATCH_SIZE*val_iternum):\n",
    "    trainY_cls.append(get_class_index(label_batch[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "17700\n",
      "11\n",
      "17700\n"
     ]
    }
   ],
   "source": [
    "print(len(trainX_fea[0]))\n",
    "print(len(trainX_fea))\n",
    "\n",
    "print(max(trainY_cls))\n",
    "print(len(trainY_cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the obtained features as npy files for subsequent use.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_fea_save = np.asarray(trainX_fea).reshape(len(trainX_fea),len(trainX_fea[0]))\n",
    "#np.save(\"EfficientNetB7_train.npy\",trainX_fea_save)\n",
    "np.save(OUTPUT_DIR + pre_trained_model_type_name + '_train.npy',trainX_fea_save)                                                \n",
    "                                                 \n",
    "\n",
    "trainY_cls_save = np.asarray(trainY_cls).reshape(len(trainY_cls), 1)\n",
    "#np.save(\"EfficientNetB7_train_label.npy\",trainY_cls_save)\n",
    "np.save(OUTPUT_DIR + pre_trained_model_type_name + '_train_label.npy',trainY_cls_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform similar operations on the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "test_iternum = test_set_len//BATCH_SIZE\n",
    "\n",
    "for i in range(test_iternum):\n",
    "    print(i)\n",
    "    img_batch, label_batch = generators.test_generator.next()\n",
    "    for j in range(len(img_batch)):\n",
    "        img_batch[j] = tf.expand_dims(img_batch[j], axis=0) \n",
    "        img_batch[j] = pre_trained_model.preprocess_input(img_batch[j])\n",
    "\n",
    "    tmp = cls_model_f.predict(img_batch)\n",
    "    for j in range(len(tmp)):\n",
    "        testX_fea.append(tmp[j])\n",
    "        \n",
    "    for j in range(len(label_batch)):\n",
    "        testY_cls.append(get_class_index(label_batch[j]))\n",
    "        \n",
    "img_batch, label_batch = generators.test_generator.next()\n",
    "for j in range(len(img_batch)):\n",
    "    img_batch[j] = tf.expand_dims(img_batch[j], axis=0) \n",
    "    img_batch[j] = pre_trained_model.preprocess_input(img_batch[j])\n",
    "\n",
    "tmp = cls_model_f.predict(img_batch)\n",
    "for j in range(test_set_len - BATCH_SIZE*test_iternum):\n",
    "    testX_fea.append(tmp[j])\n",
    "\n",
    "for j in range(test_set_len - BATCH_SIZE*test_iternum):\n",
    "    testY_cls.append(get_class_index(label_batch[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "932\n",
      "11\n",
      "932\n"
     ]
    }
   ],
   "source": [
    "print(len(testX_fea[0]))\n",
    "print(len(testX_fea))\n",
    "\n",
    "print(max(testY_cls))\n",
    "print(len(testY_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX_fea_save = np.asarray(testX_fea).reshape(len(testX_fea),len(testX_fea[0]))\n",
    "#np.save(\"EfficientNetB7_test.npy\",testX_fea_save)\n",
    "np.save(OUTPUT_DIR + pre_trained_model_type_name + '_test.npy',testX_fea_save)  \n",
    "\n",
    "testY_cls_save = np.asarray(testY_cls).reshape(len(testX_fea), 1)\n",
    "#np.save(\"EfficientNetB7_test_label.npy\",testY_cls_save)\n",
    "np.save(OUTPUT_DIR + pre_trained_model_type_name + '_test_label.npy',testY_cls_save) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Load features and Classify!\n",
    ">In this part, we will read in the previously saved features and use various classifiers to verify the strength of each basic feature. It is worth noting that in the GPU environment, we can use the cuml library provided by NVIDIA RAPIDS to greatly accelerate the training of some classifiers. The default version provided by Kaggle is 0.16.0, and we upgraded it to 0.19.0 by using the installation package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the new version RAPIDS from https://www.kaggle.com/cdeotte/rapids as input dataset\n",
    "if USE_KAGGLE == True:\n",
    "    import sys\n",
    "    !cp ../input/rapids/rapids.0.19.0 /opt/conda/envs/rapids.tar.gz\n",
    "    !cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n",
    "    sys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\n",
    "    sys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\n",
    "    sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n",
    "    !cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_KAGGLE == True:\n",
    "    import cuml\n",
    "    from cuml import linear_model\n",
    "    from cuml import multiclass\n",
    "    from cuml import svm\n",
    "    from cuml import naive_bayes\n",
    "    from cuml import decomposition\n",
    "    from cuml.ensemble import RandomForestClassifier as cuRFC\n",
    "    \n",
    "    cuml.__version__ \n",
    "else:\n",
    "    from sklearn import linear_model\n",
    "    from sklearn import ensemble\n",
    "    from sklearn import svm\n",
    "    from sklearn import multiclass\n",
    "    from sklearn import model_selection\n",
    "    from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17700, 1024)\n",
      "(17700, 1)\n",
      "(932, 1024)\n",
      "(932, 1)\n"
     ]
    }
   ],
   "source": [
    "modelname_basic = 'DenseNet121'\n",
    "\n",
    "trainX_fea = np.load(FEATURES_DIR + modelname_basic + '_train.npy')\n",
    "trainY_cls = np.load(FEATURES_DIR + modelname_basic + '_train_label.npy')\n",
    "testX_fea = np.load(FEATURES_DIR + modelname_basic + '_test.npy')\n",
    "testY_cls = np.load(FEATURES_DIR + modelname_basic + '_test_label.npy')\n",
    "\n",
    "print(trainX_fea.shape)\n",
    "print(trainY_cls.shape)\n",
    "print(testX_fea.shape)\n",
    "print(testY_cls.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LogisticRegression(ovr)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w= [[-1.89293594e-03  3.97013816e-03 -1.25525868e-02 ... -7.59595669e-02\n",
      "  -3.33544949e-01  0.00000000e+00]\n",
      " [ 6.02692917e-04  1.14744023e-02  2.62183365e-02 ... -1.86018805e+00\n",
      "  -2.10830529e+00  0.00000000e+00]\n",
      " [-8.28956477e-04 -3.37922942e-03 -6.34308808e-03 ... -7.26137848e-01\n",
      "   2.76851845e-01  0.00000000e+00]\n",
      " ...\n",
      " [ 2.66660862e-03 -3.11443841e-02 -2.37306661e-02 ...  2.35038847e+00\n",
      "   2.05615798e+00  0.00000000e+00]\n",
      " [-8.70609423e-04 -4.04474289e-03 -1.77807382e-02 ...  2.62880080e-03\n",
      "  -5.09319605e-01  0.00000000e+00]\n",
      " [-3.93536739e-04 -7.11250158e-03 -9.13027781e-04 ...  1.74625555e-01\n",
      "   1.53672134e+00  0.00000000e+00]]\n",
      "b= [ -1.07084558   2.48664938   0.11678925 -65.7266658   -2.2191831\n",
      "   0.14819038  34.15634207  -0.36417588   0.38297077   0.78384914\n",
      "  -0.71826212  -0.85939503]\n",
      "val accuracy = 0.4592274678111588\n"
     ]
    }
   ],
   "source": [
    "#Linear\n",
    "if USE_KAGGLE == True:\n",
    "    mlogreg = multiclass.MulticlassClassifier(linear_model.LogisticRegression(C=10, max_iter = 4000, class_weight='balanced'), strategy='ovr')\n",
    "    mlogreg.fit(trainX_fea, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = mlogreg.predict(testX_fea)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))\n",
    "else:\n",
    "    mlogreg = linear_model.LogisticRegression(C=10, multi_class='ovr', max_iter = 4000)\n",
    "    mlogreg.fit(trainX_fea, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    print(\"w=\", mlogreg.coef_)\n",
    "    print(\"b=\", mlogreg.intercept_)\n",
    "\n",
    "    predY_cls = mlogreg.predict(testX_fea)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LogisticRegression(multinomial)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_KAGGLE == True:\n",
    "    mlogreg_2 = multiclass.MulticlassClassifier(linear_model.LogisticRegression(C=10, max_iter = 4000, class_weight='balanced'), strategy='ovo')\n",
    "    mlogreg_2.fit(trainX_fea, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = mlogreg_2.predict(testX_fea)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))\n",
    "else:\n",
    "    mlogreg_2 = linear_model.LogisticRegression(C=10, multi_class='multinomial', max_iter = 4000)\n",
    "    mlogreg_2.fit(trainX_fea, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    print(\"w=\", mlogreg_2.coef_)\n",
    "    print(\"b=\", mlogreg_2.intercept_)\n",
    "\n",
    "    predY_cls = mlogreg_2.predict(testX_fea)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MultinomialNB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_KAGGLE == True:\n",
    "    mnbclf = naive_bayes.MultinomialNB(alpha=0.1)\n",
    "    mnbclf.fit(trainX_fea, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = mnbclf.predict(testX_fea)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OneVsRestClassifier(linear-svm)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_KAGGLE == True:\n",
    "    msvm = multiclass.OneVsRestClassifier(svm.SVC(kernel='linear'))\n",
    "    msvm.fit(trainX_fea, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = msvm.predict(testX_fea)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))\n",
    "else:\n",
    "    msvm = multiclass.OneVsRestClassifier(svm.SVC(kernel='linear'))\n",
    "    msvm.fit(trainX_fea, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = msvm.predict(testX_fea)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RBF-svm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Linear\n",
    "if USE_KAGGLE == True:\n",
    "    rbfsvm = svm.SVC(kernel='rbf', gamma='scale', C=1000)\n",
    "    rbfsvm.fit(trainX_fea, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = rbfsvm.predict(testX_fea)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))\n",
    "else:\n",
    "    rbfsvm = svm.SVC(kernel='rbf', gamma=0.1, C=1000)\n",
    "    rbfsvm.fit(trainX_fea, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = rbfsvm.predict(testX_fea)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdaBoostClassifier(n_estimators=300)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_KAGGLE == False:\n",
    "    ada=ensemble.AdaBoostClassifier(learning_rate=0.1, n_estimators=300, random_state=4487)\n",
    "    ada.fit(trainX_fea, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = ada.predict(testX_fea)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBClassifier(n_estimators=300)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_KAGGLE == False:\n",
    "    xgbclf = xgb.XGBClassifier(objective=\"multi:softprob\", learning_rate=0.1, n_estimators=300, random_state=4487)\n",
    "    xgbclf.fit(trainX_fea, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = xgbclf.predict(testX_fea)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomForestClassifier(n_estimators=2000) or RandomForestClassifier(n_estimators=1000)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_KAGGLE == True:\n",
    "    rfclf = cuRFC(n_estimators=1000, random_state=4487)\n",
    "    rfclf.fit(trainX_fea,trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = rfclf.predict(testX_fea)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))\n",
    "else:\n",
    "    rfclf = ensemble.RandomForestClassifier(n_estimators=2000, random_state=4487, n_jobs=-1)\n",
    "    rfclf.fit(trainX_fea, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = rfclf.predict(testX_fea)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The accuracy of the above classifier under each basic feature is as follows:**\n",
    "![results_1_cuml](../asserts/results_1_cuml.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Features Fusion and PCA\n",
    ">In the last part, we try to mix different basic features before making a selection. From the previous results, we know that DenseNet121, Xception and MobileNetV2 perform relatively well. We concatenate them and use the PCA of different n_components to select and get new features. And use the previous classifiers that performed well for training, and the results are as follows:\n",
    "![results_2_cuml](../asserts/results_2_cuml.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17700, 4352)\n",
      "(932, 4352)\n",
      "(17700, 2048)\n",
      "(932, 2048)\n"
     ]
    }
   ],
   "source": [
    "#mobilenet_v2.MobileNetV2\n",
    "#xception.Xception\n",
    "#densenet.DenseNet121\n",
    "#resnet_v2.ResNet50V2\n",
    "#vgg16.VGG16\n",
    "#inception_resnet_v2.InceptionResNetV2\n",
    "modelname1 = 'DenseNet121'\n",
    "modelname2 = 'Xception'\n",
    "modelname3 = 'MobileNetV2'\n",
    "PCA_n_components = 2048\n",
    "\n",
    "# feature fusion\n",
    "feature1 = np.load(FEATURES_DIR + modelname1 + '_train.npy')\n",
    "feature2 = np.load(FEATURES_DIR + modelname2 + '_train.npy')\n",
    "feature3 = np.load(FEATURES_DIR + modelname3 + '_train.npy')\n",
    "new_feature = np.concatenate((feature1, feature2, feature3), axis=1)\n",
    "#new_feature = np.concatenate((feature1, feature2), axis=1)\n",
    "print(new_feature.shape)\n",
    "\n",
    "test_feature1 = np.load(FEATURES_DIR + modelname1 + '_test.npy')\n",
    "test_feature2 = np.load(FEATURES_DIR + modelname2 + '_test.npy')\n",
    "test_feature3 = np.load(FEATURES_DIR + modelname3 + '_test.npy')\n",
    "new_test_feature = np.concatenate((test_feature1, test_feature2, test_feature3), axis=1)\n",
    "#new_test_feature = np.concatenate((test_feature1, test_feature2), axis=1)\n",
    "print(new_test_feature.shape)\n",
    "\n",
    "# feature selection\n",
    "pca = decomposition.PCA(n_components=PCA_n_components)\n",
    "W = pca.fit_transform(new_feature)\n",
    "test_W = pca.transform(new_test_feature)\n",
    "print(W.shape)\n",
    "print(test_W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(OUTPUT_DIR + modelname1+'_'+modelname2+'_'+modelname3+'_PCA'+str(PCA_n_components) + \"_train.npy\",W)\n",
    "np.save(OUTPUT_DIR + modelname1+'_'+modelname2+'_'+modelname3+'_PCA'+str(PCA_n_components) + \"_test.npy\",test_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_KAGGLE == True:\n",
    "    msvm = multiclass.OneVsRestClassifier(svm.SVC(kernel='linear'))\n",
    "    msvm.fit(W, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = msvm.predict(test_W)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))\n",
    "else:\n",
    "    msvm = multiclass.OneVsRestClassifier(svm.SVC(kernel='linear'))\n",
    "    msvm.fit(W, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = msvm.predict(test_W)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_KAGGLE == True:\n",
    "    rbfsvm = svm.SVC(kernel='rbf', gamma='scale', C=1000)\n",
    "    rbfsvm.fit(W, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = rbfsvm.predict(test_W)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))\n",
    "else:\n",
    "    rbfsvm = svm.SVC(kernel='rbf', gamma=0.1, C=1000)\n",
    "    rbfsvm.fit(W, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = rbfsvm.predict(test_W)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy = 0.36802575107296137\n"
     ]
    }
   ],
   "source": [
    "if USE_KAGGLE == True:\n",
    "    rfclf = cuRFC(n_estimators=1000, random_state=4487)\n",
    "    rfclf.fit(W,trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = rfclf.predict(test_W)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))\n",
    "else:\n",
    "    rfclf = ensemble.RandomForestClassifier(n_estimators=2000, random_state=4487, n_jobs=-1)\n",
    "    rfclf.fit(W, trainY_cls.reshape(trainY_cls.shape[0], ))\n",
    "\n",
    "    predY_cls = rfclf.predict(test_W)\n",
    "    acc = metrics.accuracy_score(testY_cls, predY_cls)\n",
    "    print(\"val accuracy = \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Under the same classifier, the best accuracy of the new feature is increased by 0.466738197 from the basic feature's 0.465665236, although this improvement is not obvious. But by adding more basic features (such as extracting more features from the middle layer of the pre-trained model), the accuracy may continue to improve.**\n",
    "![results_3_cuml](../asserts/results_3_cuml.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
