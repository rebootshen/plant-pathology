{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "#####################################\n",
    "# Libraries\n",
    "#####################################\n",
    "# Common libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Image processing\n",
    "import imageio\n",
    "import cv2\n",
    "import skimage.transform\n",
    "#from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "# Charts\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML, statistics\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "\n",
    "# Tensorflow\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "#INPUT_DIR = \"/kaggle/input/plant-pathology-2021-fgvc8/\"\n",
    "#PRETRAINED_DIR = \"/kaggle/input/pretrained-model/\"\n",
    "#NUM_CLASSES = 6 #12\n",
    "\n",
    "INPUT_DIR = \"../input/plant-pathology-2021-fgvc8/\"\n",
    "PRETRAINED_DIR = \"../input/pretrained-model/\"\n",
    "NUM_CLASSES = 6\n",
    "\n",
    "IMAGE_SIZE= (224,224)  #(256,256)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"\n",
    "    Create and fit the model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        #(18632, 2) (17700, 2) (932, 2)\n",
    "        #15930 , 1770, 932\n",
    "        \n",
    "        self.nb_train_samples = 15930 #4275 #32706\n",
    "        self.nb_validation_samples = 1770 #475 #10902\n",
    "        self.batch_size=512 #512 #32 #1024   #32\n",
    "               \n",
    "        \n",
    "        self.img_width = IMAGE_SIZE[0]\n",
    "        self.img_height = IMAGE_SIZE[1]\n",
    "        print(self.img_width,self.img_height)\n",
    "        \n",
    "    \n",
    "    def create_model(self, model_name):\n",
    "        if model_name == \"Xception\" :\n",
    "                model = self.create_model_1()\n",
    "        elif model_name == \"XceptionDenseNet121\": \n",
    "                model = self.create_model_3()\n",
    "        else:\n",
    "                print(\"Model not found\")\n",
    "        self.model_name = model_name\n",
    "        return model\n",
    "    \n",
    "\n",
    "    #Total params: 20,886,068\n",
    "    def create_model_1(self):\n",
    "        pretrained_model = tf.keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(self.img_width, self.img_height, 3))\n",
    "        model = tf.keras.models.Sequential([\n",
    "            pretrained_model,\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')\n",
    "        ])\n",
    "    \n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        #tf.keras.utils.plot_model(densenet_model, to_file='densenet_model.png')\n",
    "        return model\n",
    "\n",
    "    def create_model_3(self):\n",
    "        path1 = PRETRAINED_DIR + 'xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "        xception_model = tf.keras.models.Sequential([\n",
    "           tf.keras.applications.xception.Xception(include_top=False, weights=None, input_shape=(self.img_width, self.img_height, 3)),#(512, 512, 3)),\n",
    "           tf.keras.layers.GlobalAveragePooling2D(),\n",
    "           #tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')\n",
    "           tf.keras.layers.Dense(NUM_CLASSES,activation='sigmoid')\n",
    "        ])\n",
    "        # Freezing the weights\n",
    "        #for layer in xception_model.layers[:-1]:\n",
    "        #    layer.trainable=False\n",
    "            \n",
    "        #xception_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        #xception_model.summary()\n",
    "        path2 = PRETRAINED_DIR + 'densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "        densenet_model = tf.keras.models.Sequential([\n",
    "            tf.keras.applications.densenet.DenseNet121(include_top=False, weights=None,input_shape=(self.img_width, self.img_height, 3)),#(512, 512, 3)),\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            #tf.keras.layers.Dense(NUM_CLASSES,activation='softmax')\n",
    "            tf.keras.layers.Dense(NUM_CLASSES,activation='sigmoid')\n",
    "        ])\n",
    "        #for layer in densenet_model.layers[:-1]:\n",
    "        #    layer.trainable=False\n",
    "        #densenet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        #densenet_model.summary()\n",
    "        \n",
    "        inputs = tf.keras.Input(shape=(self.img_width, self.img_height, 3)) #(512, 512, 3))\n",
    "\n",
    "        xception_output = xception_model(inputs)\n",
    "        densenet_output = densenet_model(inputs)\n",
    "\n",
    "        outputs = tf.keras.layers.average([densenet_output, xception_output])\n",
    "\n",
    "\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 224\n"
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer()\n",
    "model = trainer.create_model(\"XceptionDenseNet121\") # 0.9062 Total params: 27,935,872\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.load_weights(PRETRAINED_DIR+'best_XceptionDenseNet121_v2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes = ['complex', 'frog_eye_leaf_spot', 'frog_eye_leaf_spot complex', 'healthy', 'powdery_mildew', 'powdery_mildew complex', 'rust', 'rust complex', 'rust frog_eye_leaf_spot', 'scab', 'scab frog_eye_leaf_spot', 'scab frog_eye_leaf_spot complex']\n",
    "classes = ['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab' ]# 'frog_eye_leaf_spot complex','powdery_mildew complex', 'rust complex', 'rust frog_eye_leaf_spot', 'scab frog_eye_leaf_spot', 'scab frog_eye_leaf_spot complex']\n",
    "class_names = ['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab']\n",
    "\n",
    "class Submitter:\n",
    "    \"\"\"\n",
    "    Predict and submit\n",
    "    \"\"\"\n",
    "    def __init__(self, model, img_size):\n",
    "        self.model = model\n",
    "        batch_size=BATCH_SIZE\n",
    "        print(\"Initializing submitter\")\n",
    "        #Submission generator\n",
    "        # flow_from_directory for input/test didn't work for me, so quick fix is to use flow_from_dataframe with list of files\n",
    "        # Load list of files from test folder into dataframe\n",
    "        self.test_files_df=pd.DataFrame()\n",
    "        TEST_DIR = INPUT_DIR + 'test_images1/'\n",
    "        self.test_files_df['image']=os.listdir(TEST_DIR)\n",
    "        print(\"Loaded test files list\")\n",
    "        \n",
    "        \n",
    "        # Create generator in it\n",
    "        #self.generator=ImageDataGenerator(rescale=1./255.).flow_from_dataframe(\n",
    "        _test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "        self.generator = _test_datagen.flow_from_dataframe(\n",
    "                    dataframe=self.test_files_df,\n",
    "                    directory=TEST_DIR,\n",
    "                    x_col=\"image\",\n",
    "                    y_col=None,\n",
    "                    #has_ext=True,\n",
    "                    class_mode=None,\n",
    "                    batch_size=batch_size,\n",
    "                    seed=42,\n",
    "                    shuffle=False,\n",
    "                    target_size=img_size)    \n",
    "        \n",
    "        print('Submission generator created')    \n",
    "\n",
    "\n",
    "    def predict_for_submit(self):\n",
    "        \"\"\"\n",
    "        Predict submission test data and form dataframe to submit\n",
    "        \"\"\"\n",
    "        print(\"Forming submission dataframe...\")\n",
    "        # Predict\n",
    "        aa= self.model.predict_proba(self.generator)\n",
    "        print(aa)\n",
    "        print(aa[:,1])\n",
    "            \n",
    "        y_pred = self.model.predict(self.generator)\n",
    "        y_pred = y_pred.tolist()\n",
    "        print(y_pred)\n",
    "        #y_pred = np.argmax(y_pred, axis=1)\n",
    "        #print(y_pred)\n",
    "        \n",
    "        indices = []\n",
    "        for pred in y_pred:\n",
    "            temp = []\n",
    "            for category in pred:\n",
    "                #print(category)\n",
    "                if category>=0.3:\n",
    "                    temp.append(pred.index(category))\n",
    "            print(temp)\n",
    "            if temp!=[]:\n",
    "                indices.append(temp)\n",
    "            else:\n",
    "                temp.append(np.argmax(pred))\n",
    "                indices.append(temp)\n",
    "        \n",
    "        print(indices)\n",
    "        \n",
    "        y_pred_str = []        \n",
    "        for image in indices:\n",
    "            temp = []\n",
    "            for i in image:\n",
    "                #if i > 5:\n",
    "                #    temp.append(classes[0])\n",
    "                #else:\n",
    "                temp.append(classes[i])\n",
    "                    \n",
    "            y_pred_str.append(' '.join(temp))\n",
    "\n",
    "        print(y_pred_str)\n",
    "        \n",
    "        self.test_files_df['labels'] = y_pred_str\n",
    "        # Write to csv\n",
    "        self.test_files_df.to_csv('./submission.csv', index=False)\n",
    "        print(\"Submission completed: written submission.csv\")\n",
    "        return self.test_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing submitter\n",
      "Loaded test files list\n",
      "Found 10 validated image filenames.\n",
      "Submission generator created\n",
      "Forming submission dataframe...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2d2379745ee7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get dataframe for submission\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msubmitter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSubmitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msubmission_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubmitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_for_submit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msubmission_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-c0f80373e0e4>\u001b[0m in \u001b[0;36mpredict_for_submit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Forming submission dataframe...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# Predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0maa\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "# Get dataframe for submission\n",
    "submitter = Submitter(model, IMAGE_SIZE)\n",
    "submission_df = submitter.predict_for_submit()     \n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800113bb65efe69e.jpg</td>\n",
       "      <td>healthy powdery_mildew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8002cb321f8bfcdf.jpg</td>\n",
       "      <td>complex frog_eye_leaf_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80070f7fb5e2ccaa.jpg</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80077517781fb94f.jpg</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800cbf0ff87721f8.jpg</td>\n",
       "      <td>complex frog_eye_leaf_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>800edef467d27c15.jpg</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>800f85dc5f407aef.jpg</td>\n",
       "      <td>rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>85f8cb619c66b863.jpg</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ad8770db05586b59.jpg</td>\n",
       "      <td>complex frog_eye_leaf_spot scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c7b03e718489f3ca.jpg</td>\n",
       "      <td>frog_eye_leaf_spot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image                           labels\n",
       "0  800113bb65efe69e.jpg           healthy powdery_mildew\n",
       "1  8002cb321f8bfcdf.jpg       complex frog_eye_leaf_spot\n",
       "2  80070f7fb5e2ccaa.jpg                             scab\n",
       "3  80077517781fb94f.jpg                             scab\n",
       "4  800cbf0ff87721f8.jpg       complex frog_eye_leaf_spot\n",
       "5  800edef467d27c15.jpg                          healthy\n",
       "6  800f85dc5f407aef.jpg                             rust\n",
       "7  85f8cb619c66b863.jpg                             scab\n",
       "8  ad8770db05586b59.jpg  complex frog_eye_leaf_spot scab\n",
       "9  c7b03e718489f3ca.jpg               frog_eye_leaf_spot"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800113bb65efe69e.jpg</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8002cb321f8bfcdf.jpg</td>\n",
       "      <td>scab frog_eye_leaf_spot complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80070f7fb5e2ccaa.jpg</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80077517781fb94f.jpg</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800cbf0ff87721f8.jpg</td>\n",
       "      <td>complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>800edef467d27c15.jpg</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>800f85dc5f407aef.jpg</td>\n",
       "      <td>cider_apple_rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>801d6dcd96e48ebc.jpg</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>801f78399a44e7af.jpg</td>\n",
       "      <td>complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8021b94d437eb7d3.jpg</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image                           labels\n",
       "0  800113bb65efe69e.jpg                          healthy\n",
       "1  8002cb321f8bfcdf.jpg  scab frog_eye_leaf_spot complex\n",
       "2  80070f7fb5e2ccaa.jpg                             scab\n",
       "3  80077517781fb94f.jpg                             scab\n",
       "4  800cbf0ff87721f8.jpg                          complex\n",
       "5  800edef467d27c15.jpg                          healthy\n",
       "6  800f85dc5f407aef.jpg                 cider_apple_rust\n",
       "7  801d6dcd96e48ebc.jpg                          healthy\n",
       "8  801f78399a44e7af.jpg                          complex\n",
       "9  8021b94d437eb7d3.jpg                          healthy"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.read_csv(INPUT_DIR + \"train.csv\")\n",
    "all_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp /kaggle/input/notebook-sam/best_XceptionDenseNet121.h5 .\n",
    "\n",
    "#import os\n",
    "#print(os.listdir(\"/kaggle/input/\"))\n",
    "#os.chdir(r'/kaggle/working')\n",
    "#from IPython.display import FileLink\n",
    "#FileLink(r'./best_XceptionDenseNet121.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(prediction,threshold):\n",
    "  pred = []\n",
    "  idx = np.where(prediction>threshold)[0]\n",
    "  for i in idx:\n",
    "    pred.append(class_names[i])\n",
    "  pred = ' '. join(pred)\n",
    "  if len(pred) == 0:\n",
    "    pred = []\n",
    "    idx = np.argmax(prediction)\n",
    "    pred.append(class_names[idx])\n",
    "    pred = ' '. join(pred)\n",
    "    return pred\n",
    "  else :\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18632, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800113bb65efe69e.jpg</td>\n",
       "      <td>[healthy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8002cb321f8bfcdf.jpg</td>\n",
       "      <td>[scab, frog_eye_leaf_spot, complex]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80070f7fb5e2ccaa.jpg</td>\n",
       "      <td>[scab]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80077517781fb94f.jpg</td>\n",
       "      <td>[scab]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800cbf0ff87721f8.jpg</td>\n",
       "      <td>[complex]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image                               labels\n",
       "0  800113bb65efe69e.jpg                            [healthy]\n",
       "1  8002cb321f8bfcdf.jpg  [scab, frog_eye_leaf_spot, complex]\n",
       "2  80070f7fb5e2ccaa.jpg                               [scab]\n",
       "3  80077517781fb94f.jpg                               [scab]\n",
       "4  800cbf0ff87721f8.jpg                            [complex]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'] = all_df['image']\n",
    "train['labels'] = all_df['labels'].apply(lambda string: string.split(' '))\n",
    "\n",
    "data = train #.sample(5000)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18632 non-validated image filenames.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6abe70bf1841>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mpredicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Tools\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tools\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tools\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mC:\\Tools\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tools\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\Tools\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tools\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_DIR = INPUT_DIR + 'train_images'\n",
    "\n",
    "full_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "full_set = full_datagen.flow_from_dataframe(dataframe=data,\n",
    "                                    directory=TRAIN_DATA_DIR,\n",
    "                                    x_col='image',\n",
    "                                    y_col= None,                                    \n",
    "                                    target_size = IMAGE_SIZE,\n",
    "                                    batch_size = BATCH_SIZE,\n",
    "                                    shuffle=False,\n",
    "                                    validate_filenames=False,\n",
    "                                    class_mode=None)\n",
    "\n",
    "\n",
    "\n",
    "predicts = model.predict(full_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "num_classes = 6\n",
    "roc_auc_macro = []\n",
    "\n",
    "for t in thresholds:\n",
    "  labels = []\n",
    "  for i in range(len(predicts)):\n",
    "    pred = predicts[i]\n",
    "\n",
    "    labels.append(get_labels(prediction = pred, threshold = t))\n",
    "  data[\"pred\"]= labels\n",
    "\n",
    "  from sklearn.preprocessing import MultiLabelBinarizer\n",
    "  mlb = MultiLabelBinarizer()\n",
    "  # binarize truth \n",
    "  mlb.fit(data[\"labels\"])\n",
    "\n",
    "  y_test = mlb.transform(data[\"labels\"])\n",
    "  # binarize pred\n",
    "  data[\"pred\"] = data[\"pred\"].str.split(\" \")\n",
    "  y_score = mlb.transform(data[\"pred\"]) \n",
    "\n",
    "  from sklearn.metrics import roc_curve, auc\n",
    "  from scipy import interp\n",
    "  from itertools import cycle\n",
    "  # Compute ROC curve and ROC area for each class\n",
    "  fpr = dict()\n",
    "  tpr = dict()\n",
    "  thresholds = dict()\n",
    "  roc_auc = dict()\n",
    "  for i in range(num_classes):\n",
    "      fpr[i], tpr[i], thresholds[i] = roc_curve(y_test[:, i], y_score[:, i])\n",
    "      roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "  # Compute micro-average ROC curve and ROC area\n",
    "  fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "  roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "  all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
    "\n",
    "  # Then interpolate all ROC curves at this points\n",
    "  mean_tpr = np.zeros_like(all_fpr)\n",
    "  for i in range(num_classes):\n",
    "      mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "  # Finally average it and compute AUC\n",
    "  mean_tpr /= num_classes\n",
    "\n",
    "  fpr[\"macro\"] = all_fpr\n",
    "  tpr[\"macro\"] = mean_tpr\n",
    "  roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "  roc_auc_macro.append(round(roc_auc[\"macro\"],2))\n",
    "\n",
    "  print(\"Threshold:\",t,\"ROC: \",round(roc_auc[\"macro\"],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "# binarize truth \n",
    "mlb.fit(data[\"labels\"])\n",
    "\n",
    "y_true = mlb.transform(data[\"labels\"])#.tolist()\n",
    "y_pred = predicts#.tolist()\n",
    "print(y_true[0])\n",
    "print(y_pred[0])\n",
    "print(y_true.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], thresholds[i] = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(num_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Class ' + str(i) + \" \"+ class_names[i])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred[0], y_true[0])\n",
    "\n",
    "#labels.append(get_labels(prediction = pred, threshold = t))\n",
    "#y_pred = y_pred.tolist()\n",
    "indices = []\n",
    "for pred in y_pred:\n",
    "    temp = []\n",
    "    for category in pred:\n",
    "        #print(category)\n",
    "        if category>=0.2:\n",
    "            temp.append(pred.index(category))\n",
    "    #print(temp)\n",
    "    if temp!=[]:\n",
    "        indices.append(temp)\n",
    "    else:\n",
    "        temp.append(np.argmax(pred))\n",
    "        indices.append(temp)\n",
    "\n",
    "#print(indices)\n",
    "y_pred1 = []\n",
    "for pred in indices:\n",
    "    item = []\n",
    "    for i in range(6):\n",
    "        if i in pred :\n",
    "            item.append(1)\n",
    "        else:\n",
    "            item.append(0)\n",
    "    #print(item)\n",
    "    y_pred1.append(item)\n",
    "\n",
    "print(y_pred1[0])\n",
    "y_true1 = y_true[:,:-1].tolist()\n",
    "print(y_true1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report( y_pred1, y_true1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "res = pd.DataFrame({'FPR': fpr[0], 'TPR': tpr[0], 'Threshold': thresholds[0]})  #0 0.25  #1 0.7\n",
    "aa = res[['TPR', 'FPR', 'Threshold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 999)\n",
    "aa.loc[(aa['TPR'] >= 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"thresholds\"]= thresholds\n",
    "df[\"roc_auc_macro\"]= roc_auc_macro\n",
    "df.sort_values(\"roc_auc_macro\", inplace=True, ascending=False)\n",
    "df.reset_index(inplace=True, drop = True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
